[CMSSW]
#signal has 1508 events
#background has 1187 events
#background herwig has 663 events
#herwig has x events
#total_number_of_events=4335599
#total_number_of_events=25733201
#number_of_jobs=500

#JSON: per usare il json scommentare le seguenti righe e commentare quelle qui sopra
#punto 1bis: come usare il json. da twiki https://twiki.cern.ch/twiki/bin/viewauth/CMS/LumiSelJson
#lumi_mask=json_27May.json
#lumi_mask=Cert_136033-149442_7TeV_Dec22ReReco_Collisions10_JSON_v3.txt
lumi_mask=Cert_160404-163757_7TeV_PromptReco_Collisions11_JSON.txt
total_number_of_lumis=-1
lumis_per_job=50

#nome del pyton che si vuole usare
#pset=SimAnalyzer_cfg.py
#pset=WH_channel_cfg.py
#pset=ZH_channel_cfg.py
#pset=ZH_channel_filter.py
#pset=WH_channel_filter.py
#pset=MultiJet_filter_cfg.py
pset=GammaJet_data_cfg.py

# dbs instance: cms_dbs_ph_analysis_02
#dbs_url = http://cmsdbsprod.cern.ch/cms_dbs_ph_analysis_02/servlet/DBSServlet

#stringa presa dal dbs dei dati che si vogliono processare
#queste le ho prese seguendo la twiki https://twiki.cern.ch/twiki/bin/viewauth/CMS/Collisions2010Analysis#Luminosity_and_number_of_recorde
#datasetpath=/MinimumBias/Commissioning10-SD_Mu-Jun14thSkim_v1/RECO #2PD era
#datasetpath=/Mu/Run2010A-Jun14thReReco_v1/RECO #8PD era
#datasetpath=/MultiJet/Run2010B-PromptReco-v2/AOD
#datasetpath=/MultiJet/Run2010B-PromptReco-v2/RECO
#queste sono le pattuple fatte da leo
#datasetpath=/Jet/leo-BJetsPatDumpV11B-CMSSW_3_8_6-Run2010B-Nov4ReReco_v1-cc1e2c49f9b59d7544999ef93147bb1f/USER
datasetpath=/Photon/Run2011A-PromptReco-v2/AOD
#/Photon/Run2011A-PromptReco-v2/AOD 
#datasetpath=/G_Pt_120to170_TuneZ2_7TeV_pythia6/Fall10-START38_V12-v1/AODSIM
#datasetpath=G_Pt_170to300_TuneZ2_7TeV_pythia6/Fall10-START38_V12-v1/AODSIM
#datasetpath=/QCD_Pt300/Summer10-START36_V9_S09-v1/AODSIM
#datasetpath=/W2Jets_ptW-100to300_TuneZ2_7TeV-alpgen-tauola/Fall10-START38_V12-v1/GEN-SIM-RECO
#datasetpath=/ZinvisibleJets_MadGraph_GEN_FASTSIM_HLT_CMSSW_3_8_6_7TeV/bortigno-ZinvisibleJets_MadGraph_GEN_FASTSIM_HLT_CMSSW_3_8_6_7TeV-f7a939540ea585b9611e2e52a6c14d5b/USER
#datasetpath=/WH_WToLNu_HToBB_M-120_7TeV-powheg-herwigpp/Fall10-START38_V12-v1/AODSIM
#datasetpath=/ZH_ZToLL_HToBB_M-120_7TeV-powheg-herwigpp/Fall10-START38_V12-v1/AODSIM
#datasetpath=/ZJets_ZToLL_ZPt150ToInf_7TeV-herwigpp/schiefer-CMSSW_3_8_6-START38_V13_FastSim-v1/AODSIM
#datasetpath=none
#datasetpath=/WJets_WToLNu_WPt100ToInf_7TeV-MadGraph4_CMSSW_3_8_6_InitialPU_FastSim/bortigno-WJets_WToLNu_WPt100ToInf_7TeV-MadGraph4_CMSSW_3_8_6_InitialPU_FastSim-64a72596157fc78b3f56883d1d1bed9f/USER
#datasetpath=/ZJets_WToLNu_WPt100ToInf_7TeV-MadGraph4_CMSSW_3_8_6_InitialPU_FastSim/bortigno-ZJets_WToLNu_WPt100ToInf_7TeV-MadGraph4_CMSSW_3_8_6_InitialPU_FastSim-760214ea59a6443620aad69017510915/USER

#per usare la 2 files options
#use_parents=1

#qui si puo specificare il range di lumisection da usare
#vedi wiki https://twiki.cern.ch/twiki/bin/viewauth/CMS/Collisions2010Analysis#Luminosity_and_number_of_recorde
#i dati sono invece quelli del reprocessing del 14 giugno.
#runselection=131511-137436
#runselection=136033-149442

#nome dell ouput file (deve essere uguale a quello del python).
#crab ne crea tanti quanti sono i job in cui si decidere di dividere il lavoro. la numerazione e automatica
#output_file=SimAnalyzer_WJets.root
#output_file=Ntuple_Commissioning10-SD_Mu-Jun14thSkim_v1.root
#output_file=WH_channel.root
#output_file=MultiJet_selectedEvents.root
output_file=GammaJetHLT.root
#output_file=WHchannel_selectedEvents.root
#output_file=ZH_channel.root

#boh
#skip_TFileService_output = 1
get_edm_output=1

[USER]
#1 te li copia nel tuo indirizzo se scegli zero te li mette nello storage element
return_data=1
email=pierluigi.bortignon@cern.ch

#copy to storage e l'opposto di return data
copy_data=0
#se copy data = 0 non importa quale sia lo storage element

#scelta dello storage element dove viene salvato l'output
#per salvarli su castor
#storage_element=srm-cms.cern.ch
#storage_element=T3_CH_PSI
#storage_element=T2_CH_CSCS
#storage_element = T2_IT_Legnaro

#mettere il nome di una spttodirectory della directory dove c'e il crab.cfg che non deve esiostere. la crea direttamente crab
#ui_working_dir=/afs/cern.ch/user/b/bortigno/scratch0/CMSSW_3_8_5/src/
#ui_working_dir=/home/bortigno/CMSSW_3_6_1_patch4/src/ppMuMuX/MyCode/MyNtupleMaker/test/crab_working_dir/
#ui_working_dir=./SimAnalyzer_WJets
#ui_working_dir=./ZH_channel_cut/ZH_channel_background
#ui_working_dir=./ZH_channel_cut/ZH_channel_signal
ui_working_dir=./GammaJet_data_v2_V1

#lui crea automaticamente la cartella dove mettera l output
#user_remote_dir=IVF_tuning/
#user_remote_dir=MultiMu_Ntuple/Commissioning10-SD_Mu-Jun14thSkim_v1/
#user_remote_dir=ZH_channel
#user_remote_dir=WH_channel

### se si usa LFS :this directory is the mountpoin of SE
#storage_path=/castor/cern.ch
#user_remote_dir=/user/b/bortigno/NomeCartellaDaUsare

#publish_data = 1
#publish_data_name = myprocessingCMSSW_2_2_13
#dbs_url_for_publication = https://cmsdbsprod.cern.ch:8443/cms_dbs_ph_analysis_01_writer/servlet/DBSServlet

[GRID]
#white lis dice i soli siti che si vogliono usare
#CE_white_list=T2_CH_CSCS
#SE_white_list = T0_CH_CERN
#SE_white_list = cmssrm.fnal.gov
#SE_black_list=
#CE_black_list=T0,T1,T2_AT_Vienna,T2_IT_Legnaro,T2_CH_CSCS,T2_TW_Taiwan,T2_PT_LIP_Lisbon,T2_UA_KIPT,T2_RU_ITEP,T2_UK_SGrid_RALPP,T2_TR_METU,T2_PL_Warsaw
SE_black_list=T0,T1,T2_US_Nebraska,T2_US_Florida,T2_US_MIT,T2_CN_Beijing,T2_IT_Rome,T2_RU_JINR,T2_UK_London_Brunel,T2_FR_GRIF_LLR,T2_TR_METU,T2_BE_UCL,T2_IT_Bari,T2_UA_KIPT,T2_RU_ITEP,T2_RU_PNPI,T2_EE_Estonia,.ru
CE_black_list=T0,T1,T2_US_Nebraska,T2_US_Florida,T2_US_MIT,T2_CN_Beijing,T2_IT_Rome,T2_RU_JINR,T2_UK_London_Brunel,T2_FR_GRIF_LLR,T2_TR_METU,T2_BE_UCL,T2_IT_Bari,T2_UA_KIPT,T2_RU_ITEP,T2_RU_PNPI,T2_EE_Estonia,.ru
[CRAB]
use_server=0
jobtype=cmssw
#standard
scheduler=glite
#per usarlo sui T3/T2 psi e cscs
#scheduler=sge

#per usarlo su LFS cioe sottomettere a bsub tramite grid si potrebbe fare
#scheduler=lsf

#quindi impostiamo le code, l'output, etc di lfs/caf
#[CAF]
#queue=cmscaf1nd

